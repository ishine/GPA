# -*- coding: utf-8 -*-
import gradio as gr
import os
import sys
import torch
import argparse
import librosa
import soundfile as sf

# Add inference directory to path to import gpa_inference
sys.path.append(
    os.path.abspath(os.path.join(os.path.dirname(__file__), "../inference"))
)
from gpa_inference import GPAInference

# Global inference object placeholder
inference = None


def preprocess_audio(audio_path):
    """Ensure audio is 16kHz mono"""
    if not audio_path:
        return None
    try:
        # Load audio with librosa: automatically resamples to sr=16000 and converts to mono
        y, _ = librosa.load(audio_path, sr=16000, mono=True)

        # Save processed audio to a new file to avoid conflicts
        dir_name = os.path.dirname(audio_path)
        base_name = os.path.basename(audio_path)
        name, ext = os.path.splitext(base_name)
        new_path = os.path.join(dir_name, f"{name}_16k.wav")

        sf.write(new_path, y, 16000)
        print(f"Preprocessed audio saved to: {new_path}")
        return new_path
    except Exception as e:
        print(f"Error processing audio {audio_path}: {e}")
        return audio_path


# ======================== Interface Call Logic ========================

def process_stt(audio_path):
    global inference
    if inference is None:
        return "Model not initialized."

    if not audio_path:
        return "Please upload audio first."

    # Preprocess audio
    audio_path = preprocess_audio(audio_path)

    # Direct inference call
    return inference.run_stt(audio_path=audio_path, do_sample=False)

def process_tts_a(text, ref_audio):
    global inference
    if inference is None:
        return None

    if not text or not ref_audio:
        return None

    # Preprocess audio
    ref_audio = preprocess_audio(ref_audio)

    # Direct inference call
    return inference.run_tts(
        task="tts-a",
        output_filename="tts_output.wav",
        text=text,
        ref_audio_path=ref_audio,
        temperature=0.8,
        do_sample=True,
    )

def process_vc(src_audio, ref_audio):
    global inference
    if inference is None:
        return None

    if not src_audio or not ref_audio:
        return None

    # Preprocess audio
    src_audio = preprocess_audio(src_audio)
    ref_audio = preprocess_audio(ref_audio)

    # Direct inference call
    return inference.run_vc(
        source_audio_path=src_audio,
        ref_audio_path=ref_audio,
        output_filename="vc_output.wav",
    )

# ======================== Gradio UI Layout ========================

# Use a soft, premium theme with indigo/slate colors to replace the default orange
theme = gr.themes.Soft(
    primary_hue="indigo",
    secondary_hue="slate",
    neutral_hue="slate",
    font=[gr.themes.GoogleFont("Inter"), "ui-sans-serif", "system-ui", "sans-serif"],
)

with gr.Blocks(title="General Purpose Audio System", theme=theme) as demo:
    gr.Markdown("# General Purpose Audio System")
    gr.Markdown("STT, TTS, and VC full-feature demo interface based on GPAEngine.")

    with gr.Tabs():
        # --- STT Tab ---
        with gr.TabItem("üéôÔ∏è Speech to Text (STT)"):
            with gr.Row():
                stt_input = gr.Audio(label="Input Audio", type="filepath")
                stt_output = gr.Textbox(label="Recognition Result", placeholder="Recognition result will be displayed here in real-time...", lines=5)
            stt_btn = gr.Button("Start Recognition", variant="primary")
            stt_btn.click(process_stt, inputs=stt_input, outputs=stt_output)

        # --- TTS-A Tab ---
        with gr.TabItem("üë§ Text to Speech (TTS)"):
            with gr.Row():
                with gr.Column():
                    ttsa_text = gr.Textbox(label="Synthesis Text", value="Hello, I am generated by voice cloning.")
                    ttsa_ref = gr.Audio(label="Reference Audio (Voice Source)", type="filepath")
                ttsa_output = gr.Audio(label="Synthesis Result")
            ttsa_btn = gr.Button("Synthesize Now", variant="primary")
            ttsa_btn.click(process_tts_a, inputs=[ttsa_text, ttsa_ref], outputs=ttsa_output)

        # --- VC Tab ---
        with gr.TabItem("üé≠ Voice Conversion (VC)"):
            with gr.Row():
                with gr.Column():
                    vc_src = gr.Audio(label="Source Audio (Content Source)", type="filepath")
                    vc_ref = gr.Audio(label="Reference Audio (Voice Source)", type="filepath")
                vc_output = gr.Audio(label="Conversion Result")
            vc_btn = gr.Button("Start Conversion", variant="primary")
            vc_btn.click(process_vc, inputs=[vc_src, vc_ref], outputs=vc_output)


def parse_args():
    parser = argparse.ArgumentParser(description="GPA Audio System GUI")

    # Model Paths
    parser.add_argument(
        "--tokenizer_path",
        type=str,
        default="/data3/gpa_ckpt/gpa_final/glm-4-voice-tokenizer",
        help="Path to GLM4 tokenizer",
    )
    parser.add_argument(
        "--text_tokenizer_path",
        type=str,
        default="/data3/gpa_ckpt/gpa_final",
        help="Path to text tokenizer",
    )
    parser.add_argument(
        "--bicodec_tokenizer_path",
        type=str,
        default="/data3/gpa_ckpt/gpa_final/BiCodec/",
        help="Path to BiCodec tokenizer",
    )
    parser.add_argument(
        "--gpa_model_path",
        type=str,
        default="/data3/gpa_ckpt/gpa_final",
        help="Path to GPA model",
    )

    # System Config
    parser.add_argument(
        "--output_dir",
        type=str,
        default="./output_gui",
        help="Directory to save output files",
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda" if torch.cuda.is_available() else "cpu",
        help="Device to use",
    )

    # Server Config
    parser.add_argument(
        "--server_name", type=str, default="0.0.0.0", help="Address for Gradio server"
    )
    parser.add_argument(
        "--server_port", type=int, default=7868, help="Port for Gradio server"
    )

    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()

    # Instantiate Model
    print(f"Initializing GPA Inference System on {args.device}...")
    os.makedirs(args.output_dir, exist_ok=True)

    inference = GPAInference(
        tokenizer_path=args.tokenizer_path,
        text_tokenizer_path=args.text_tokenizer_path,
        bicodec_tokenizer_path=args.bicodec_tokenizer_path,
        gpa_model_path=args.gpa_model_path,
        output_dir=args.output_dir,
        device=args.device,
    )

    # Launch Gradio Demo
    demo.queue().launch(server_name=args.server_name, server_port=args.server_port)
